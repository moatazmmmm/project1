{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# 03_hyperparameter_tuning.ipynb (ØªØ­Ø¯ÙŠØ«)\n",
    "# =====================================================\n",
    "\n",
    "# ----------------------\n",
    "# 1ï¸âƒ£ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import keras_tuner as kt\n",
    "\n",
    "# ----------------------\n",
    "# 2ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "# ----------------------\n",
    "data = pd.read_csv('/content/dataset/Heart_Disease_Prediction.csv')\n",
    "\n",
    "# ØªØ±Ù…ÙŠØ² Ø§Ù„Ù‡Ø¯Ù\n",
    "data['Heart Disease'] = data['Heart Disease'].apply(lambda x: 1 if x=='Presence' else 0)\n",
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù‡Ø¯Ù\n",
    "X = data.drop('Heart Disease', axis=1)\n",
    "y = data['Heart Disease']\n",
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Train-Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# 3ï¸âƒ£ Ø¯Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ù€ Keras Tuner\n",
    "# ----------------------\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "    # Ø¹Ø¯Ø¯ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ© Ù…Ù† 2 Ø¥Ù„Ù‰ 5\n",
    "    for i in range(hp.Int('num_layers', 2, 5)):\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', 32, 256, step=32),\n",
    "            activation=hp.Choice(f'activation_{i}', ['relu', 'elu', 'leaky_relu'])\n",
    "        ))\n",
    "        model.add(layers.Dropout(hp.Choice(f'dropout_{i}', [0.0, 0.2, 0.3, 0.5])))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ----------------------\n",
    "# 4ï¸âƒ£ ØªØ´ØºÙŠÙ„ Keras Tuner\n",
    "# ----------------------\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='tuner_results',\n",
    "    project_name='heart_disease_fcnn'\n",
    ")\n",
    "\n",
    "tuner.search(X_train, y_train, epochs=30, validation_split=0.2, batch_size=32, verbose=1)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(\"Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª Hyperparameters:\", best_hps.values)\n",
    "\n",
    "# ----------------------\n",
    "# 5ï¸âƒ£ ØªØ¬Ø±Ø¨Ø© Batch Size Ù…Ø®ØªÙ„ÙØ©\n",
    "# ----------------------\n",
    "batch_sizes = [16, 32, 64, 128]\n",
    "batch_results = {}\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    model = build_model(best_hps)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=bs,\n",
    "        verbose=0\n",
    "    )\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    batch_results[bs] = val_acc\n",
    "\n",
    "# ----------------------\n",
    "# 6ï¸âƒ£ ØªØ¬Ø±Ø¨Ø© Regularization Ù…Ø®ØªÙ„ÙØ©\n",
    "# ----------------------\n",
    "regularizations = ['none', 'dropout', 'l2', 'batchnorm']\n",
    "reg_results = {}\n",
    "\n",
    "for reg in regularizations:\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01) if reg=='l2' else None))\n",
    "\n",
    "    if reg=='batchnorm':\n",
    "        model.add(layers.BatchNormalization())\n",
    "    if reg=='dropout':\n",
    "        model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, verbose=0)\n",
    "    val_acc = history.history['val_accuracy'][-1]\n",
    "    reg_results[reg] = val_acc\n",
    "\n",
    "# ----------------------\n",
    "# 7ï¸âƒ£ ØªØ¬Ø±Ø¨Ø© Activation Functions Ùˆ Optimizers\n",
    "# ----------------------\n",
    "activations = ['relu', 'elu', 'leaky_relu']\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "act_opt_results = {}\n",
    "\n",
    "for act in activations:\n",
    "    for opt in optimizers:\n",
    "        model = keras.Sequential()\n",
    "        model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "        model.add(layers.Dense(64, activation=act))\n",
    "        model.add(layers.Dense(32, activation=act))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, verbose=0)\n",
    "        val_acc = history.history['val_accuracy'][-1]\n",
    "        act_opt_results[f'{act}_{opt}'] = val_acc\n",
    "\n",
    "# ----------------------\n",
    "# 8ï¸âƒ£ Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨ØµØ±ÙŠÙ‹Ø§\n",
    "# ----------------------\n",
    "\n",
    "# Batch Size\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(batch_results.keys(), batch_results.values())\n",
    "plt.xlabel('Batch Size')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('ØªØ£Ø«ÙŠØ± Ø­Ø¬Ù… Ø§Ù„Ø¯ÙÙØ¹Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡')\n",
    "plt.show()\n",
    "\n",
    "# Regularization\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(reg_results.keys(), reg_results.values())\n",
    "plt.xlabel('Regularization')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('ØªØ£Ø«ÙŠØ± Ø·Ø±Ù‚ Ø§Ù„ØªÙ†Ø¸ÙŠÙ… Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡')\n",
    "plt.show()\n",
    "\n",
    "# Activation + Optimizer\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(act_opt_results.keys(), act_opt_results.values())\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Activation + Optimizer')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('ØªØ£Ø«ÙŠØ± Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙØ¹ÙŠÙ„ Ùˆ Optimizers Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡')\n",
    "plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# 9ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©\n",
    "# ----------------------\n",
    "results_df = pd.DataFrame({\n",
    "    'Batch Size': list(batch_results.keys()),\n",
    "    'Validation Accuracy': list(batch_results.values())\n",
    "})\n",
    "reg_df = pd.DataFrame({\n",
    "    'Regularization': list(reg_results.keys()),\n",
    "    'Validation Accuracy': list(reg_results.values())\n",
    "})\n",
    "act_opt_df = pd.DataFrame({\n",
    "    'Activation_Optimizer': list(act_opt_results.keys()),\n",
    "    'Validation Accuracy': list(act_opt_results.values())\n",
    "})\n",
    "\n",
    "print(results_df)\n",
    "print(reg_df)\n",
    "print(act_opt_df)\n",
    "\n",
    "# Ø­ÙØ¸ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„\n",
    "results_df.to_csv('batch_size_results.csv', index=False)\n",
    "reg_df.to_csv('regularization_results.csv', index=False)\n",
    "act_opt_df.to_csv('activation_optimizer_results.csv', index=False)\n",
    "\n",
    "# ----------------------\n",
    "# ðŸ”Ÿ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„ Ø¹Ù„Ù‰ Test Set\n",
    "# ----------------------\n",
    "y_pred = (best_model.predict(X_test) > 0.5).astype('int32')\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
